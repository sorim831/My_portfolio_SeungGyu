{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPrmswg9O4jxXubc9teLOOZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import pandas as pd\n","import numpy as np\n","import openpyxl\n","from geopy.distance import geodesic\n","from math import sin, cos, radians\n","import seaborn as sns\n","from sklearn.cluster import DBSCAN\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import silhouette_score, calinski_harabasz_score\n","from sklearn.cluster import KMeans\n","from scipy.spatial.distance import cdist\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import silhouette_score\n","from shapely.geometry import Polygon\n","from sklearn.metrics import pairwise_distances\n","from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n","from geopy.distance import great_circle\n","from tqdm import tqdm\n","tqdm.pandas()"],"metadata":{"id":"5aUnTHCHoJBv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-D9VNorqlnay"},"outputs":[],"source":["# 데이터프레임의 열 이름 변경\n","fire = fire.rename(columns={'지역':'시군구'})\n","road = road.rename(columns={'lat':'위도','long':'경도'})\n","wind = wind.rename(columns={'일시':'DATE'})\n","kor = kor.rename(columns={'latitude':'위도','longitude':'경도'})\n","kor1 = kor1.rename(columns={'latitude':'위도','longitude':'경도'})\n","kor1['시군구'] = kor1['do'] + ' ' + kor1['city']\n","wind.drop(['Unnamed: 0'],axis=1,inplace=True)"]},{"cell_type":"code","source":["# 각 데이터셋에서 고유한 날짜를 가져옴\n","unique_dates1 = set(fire['DATE'])\n","unique_dates2 = set(road['DATE'])\n","unique_dates3 = set(wind['DATE'])\n","\n","all_unique_dates = sorted(unique_dates1.union(unique_dates2).union(unique_dates3))\n","\n","expanded_rows = []\n","\n","# 'kor' 데이터프레임의 각 행을 반복하면서 각 고유 날짜에 대해 새로운 행을 생성\n","for _, row in kor.iterrows():\n","    for date in all_unique_dates:\n","        new_row = row.copy()\n","        new_row['DATE'] = date\n","        expanded_rows.append(new_row)\n","\n","kor = pd.DataFrame(expanded_rows)"],"metadata":{"id":"Tg1ETOiQml6C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 'kor'을 기준으로 각 데이터셋을 'DATE'와 '시군구' 열을 사용해 병합\n","fire_ko = pd.merge(kor, fire, how='outer',on=['DATE','시군구'])\n","road_ko = pd.merge(kor, road, how='outer',on=['DATE','시군구'])\n","wind_ko = pd.merge(kor, wind, how='outer',on=['DATE','시군구'])\n","\n","fire_ko = fire_ko.rename(columns={'위도_y':'위도_화력','경도_y':'경도_화력',\n","                                  '위도_x':'위도_행정','경도_x':'경도_행정'})\n","road_ko = road_ko.rename(columns={'위도_y':'위도_도로','경도_y':'경도_도로',\n","                                  '위도_x':'위도_행정','경도_x':'경도_행정'})\n","wind_ko = wind_ko.rename(columns={'위도_y':'위도_풍향','경도_y':'경도_풍향',\n","                                  '위도_x':'위도_행정','경도_x':'경도_행정'})\n","fire_ko.drop(['발전소 이름'],axis=1,inplace=True)\n","road_ko.drop(['도로명','시작점','종점','측정거리(km)','상태'],axis=1,inplace=True)\n","wind_ko.drop(['관리관서','지점번호','최대풍속(m/s)','최대순간풍속풍향(deg)','최대순간풍속시각',\n","              '최대순간풍속풍향(deg)','최대순간풍속(m/s)'],axis=1,inplace=True)"],"metadata":{"id":"SlcOPie-mvoU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged = pd.merge(wind_ko,road_ko,how='outer',on=['DATE','시군구'])\n","merged.drop(['경도_행정_y','위도_행정_y','지점주소','지점명_x'],axis=1,inplace=True)\n","merged = merged.rename(columns={'위도_행정_x':'위도_행정','경도_행정_x':'경도_행정'})\n","merged = pd.merge(merged,fire_ko,how='outer',on=['DATE','시군구'])\n","merged = merged.rename(columns={'위도_행정_x':'위도_행정','경도_행정_x':'경도_행정'})\n","merged.drop(['경도_행정_y','위도_행정_y','최대풍속시각'],axis=1,inplace=True)"],"metadata":{"id":"s1JndcErm0k-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 각 데이터셋에서 관련된 모든 좌표를 결합하여 클러스터링 정보 생성\n","cluster_info = pd.concat([kor[['위도', '경도']],\n","                         wind[['위도', '경도']],\n","                         road[['위도', '경도']],\n","                         fire[['위도', '경도']]])\n","cluster_info = cluster_info.drop_duplicates().reset_index(drop=True)\n","\n","kmeans = KMeans(n_clusters=5, init='k-means++', random_state=42)\n","cluster_info['cluster'] = kmeans.fit_predict(cluster_info)\n","\n","lat_lon_columns = [\n","    ('위도_행정', '경도_행정'),\n","    ('위도_풍향', '경도_풍향'),\n","    ('위도_도로', '경도_도로'),\n","    ('위도_화력', '경도_화력')\n","]\n","\n","new_data = pd.DataFrame()\n","\n","for lat_col, lon_col in lat_lon_columns:\n","    temp_df = merged[[lat_col, lon_col]].dropna()\n","    temp_df.columns = ['위도', '경도']\n","    new_data = pd.concat([new_data, temp_df])\n","\n","new_data = new_data.drop_duplicates().reset_index(drop=True)\n","\n","kmeans = KMeans(n_clusters=5, init='k-means++', random_state=42)\n","new_data['cluster'] = kmeans.fit_predict(new_data)"],"metadata":{"id":"KJrOsPzym4KS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df_17\n","\n","# 필요한 컬럼 이름 리스트\n","columns_common = ['시군구', 'DATE', '평균풍속(m/s)', '최대풍속풍향(deg)', '기온(℃)', '습도(%)', '재비산먼지 평균농도(㎍/㎥)', '연료원', '발전량(MWh)', '용량(MW)', 'cluster']\n","\n","# 새로운 데이터프레임을 저장할 리스트\n","new_rows = []\n","\n","# 각 위치 유형(행정, 풍향, 도로, 화력)에 대해 위도/경도가 비어 있지 않으면 새로운 행 생성\n","for idx, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing rows\"):\n","    # 행정 위치에 대한 행\n","    if not pd.isnull(row['경도_행정']) and not pd.isnull(row['위도_행정']):\n","        new_row = [row['경도_행정'], row['위도_행정']] + [row[col] for col in columns_common]\n","        new_rows.append(new_row)\n","\n","    # 풍향 위치에 대한 행\n","    if not pd.isnull(row['경도_풍향']) and not pd.isnull(row['위도_풍향']):\n","        new_row = [row['경도_풍향'], row['위도_풍향']] + [row[col] for col in columns_common]\n","        new_rows.append(new_row)\n","\n","    # 도로 위치에 대한 행\n","    if not pd.isnull(row['경도_도로']) and not pd.isnull(row['위도_도로']):\n","        new_row = [row['경도_도로'], row['위도_도로']] + [row[col] for col in columns_common]\n","        new_rows.append(new_row)\n","\n","    # 화력 위치에 대한 행\n","    if not pd.isnull(row['경도_화력']) and not pd.isnull(row['위도_화력']):\n","        new_row = [row['경도_화력'], row['위도_화력']] + [row[col] for col in columns_common]\n","        new_rows.append(new_row)\n","\n","new_columns = ['경도', '위도'] + columns_common\n","new_df = pd.DataFrame(new_rows, columns=new_columns)\n","\n","\n","columns_to_fill = ['발전량(MWh)', '용량(MW)', '재비산먼지 평균농도(㎍/㎥)', '평균풍속(m/s)','최대풍속풍향(deg)','연료원']\n","\n","\n","# 역거리 가중치를 사용하여 클러스터 내 결측값을 채우는 함수.\n","def inverse_distance_weighting(df, target_col, cluster_col='cluster', lat_col='위도_행정', lon_col='경도_행정'):\n","    clusters = df[cluster_col].unique()\n","    filled_values = []\n","\n","    for cluster in tqdm(clusters, desc=f'Processing {target_col}', leave=False):\n","        cluster_data = df[df[cluster_col] == cluster]\n","        known_values = cluster_data.dropna(subset=[target_col])\n","        missing_values = cluster_data[cluster_data[target_col].isnull()]\n","\n","        if not known_values.empty and not missing_values.empty:\n","            known_coords = known_values[[lat_col, lon_col]].values\n","            missing_coords = missing_values[[lat_col, lon_col]].values\n","\n","            distances = cdist(missing_coords, known_coords, 'euclidean')\n","            weights = 1 / (distances + 1e-10)  # 작은 값을 더해 안정화\n","\n","            # missing_values의 인덱스를 재설정하고, 기존 인덱스를 저장합니다.\n","            missing_values = missing_values.reset_index()\n","            missing_values.rename(columns={'index': 'original_index'}, inplace=True)\n","\n","            for idx, row in missing_values.iterrows():\n","                weights_sum = np.sum(weights[idx])\n","                if weights_sum == 0:\n","                    continue\n","                if np.issubdtype(known_values[target_col].dtype, np.number):\n","                    weighted_avg = np.sum(weights[idx] * known_values[target_col].values) / weights_sum\n","                    original_index = row['original_index']\n","                    df.at[original_index, target_col] = weighted_avg\n","                    filled_values.append((original_index, weighted_avg))\n","                else:\n","                    # 비숫자 열 처리 (예: 가장 빈번한 값 찾기)\n","                    most_frequent_value = known_values[target_col].mode()[0]\n","                    original_index = row['original_index']\n","                    df.at[original_index, target_col] = most_frequent_value\n","                    filled_values.append((original_index, most_frequent_value))\n","\n","        elif not missing_values.empty:\n","            if np.issubdtype(df[target_col].dtype, np.number):\n","                global_mean = df[target_col].mean()\n","            else:\n","                # 숫자가 아닌 열의 경우 가장 빈번한 값 가져오기\n","                global_mean = df[target_col].mode()[0]\n","\n","            if pd.isnull(global_mean):\n","                continue\n","            missing_values = missing_values.reset_index()\n","            missing_values.rename(columns={'index': 'original_index'}, inplace=True)\n","            for idx, row in missing_values.iterrows():\n","                original_index = row['original_index']\n","                df.at[original_index, target_col] = global_mean\n","                filled_values.append((original_index, global_mean))\n","\n","    return df, filled_values\n","\n","for col in columns_to_fill:\n","    df_17, filled_values = inverse_distance_weighting(df_17, col)"],"metadata":{"id":"AcmF9SZ6m8Fy"},"execution_count":null,"outputs":[]}]}